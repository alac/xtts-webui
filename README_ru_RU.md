# XTTS-WebUI

## Портативная версия

У проекта появилась портативная версия, вам больше не прийдется мучаться устанавливая все зависимости.

[Нажмите здесь, чтобы скачать](https://huggingface.co/daswer123/xtts_portable/resolve/main/xtts-webui-v1_0-portable.zip?download=true)

Для запуска вам ненужно ничего кроме, Windows и видеокарты от Nvidia с 6 ГБ видеопамяти.

## Вкладка Train не работает, если вы хотите обучить модель, используйте отдельный webui.
## [xtts-finetune-webui](https://github.com/daswer123/xtts-finetune-webui)

## Readme доступен на следущих языках

[English](https://github.com/daswer123/xtts-webui/blob/main/README.md)

[Russian](https://github.com/daswer123/xtts-webui/blob/main/README_ru_RU.md)

[Português](https://github.com/daswer123/xtts-webui/blob/main/README_pt-BR.md)

## О проекте
XTTS-Webui - это веб-интерфейс, позволяющий максимально использовать возможности XTTS. В этом интерфейсе есть и другие нейронные сети, которые улучшат результат работы XTTS. Вы также можете сделать тренировку XTTS и получить высококачественную модель голоса.

![image](https://github.com/daswer123/xtts-webui/assets/22278673/89eb50c5-9a1e-41cf-8ae9-b734761716a6)

## Особенности
- Простая работа с XTTSv2
- Пакетная обработка для озвучки большого кол-ва файлов
- Возможность переводить любые аудиозаписи с сохранением голоса
- Способность автоматически улучшать результаты синтеза с помощью других нейронных сетей и аудиоинструментов
- Возможность натренировать модели и ее сразу использовать её
- Умение использовать такие инструменты, как: **RVC**, **OpenVoice**, **Resemble Enhance**, как вместе, так и по отдельности
- Возможность настройки генерации XTTS, всех параметров, несколько образцов говорящего

## TODO
- [x] Добавьте статус с информацией о ходе выполнения и ошибках
- [x] Интеграция обучения в стандартный интерфейс
- [ ] Добавьте возможность получить результат сразу ( с помощью стриминга )
- [ ] Добавить новый способ обработки текста
- [ ] Добавьте возможность настраивать говорящих при пакетной обработке
- [ ] Добавить API

## Installation

Используйте этот веб-интерфейс через [Google Colab](https://colab.research.google.com/drive/1MrzAYgANm6u79rCCQQqBSoelYGiJ1qYL)

**Убедитесь, что у вас установлены Python 3.10.x или Python 3.11, CUDA 11.8 или CUDA 12.1, Microsoft Builder Tools 2019 с пакетом c++ и ffmpeg**.

### 1 Метод, с помощью скриптов

#### Windows
Чтобы начать:
- Запустите 'install.bat' файл
- Чтобы запустить веб-интерфейс, запустите 'start_xtts_webui.bat'
- Откройте предпочтительный браузер и перейдите по локальному адресу, отображаемому в консоли.

#### Linux
Чтобы начать:
- Запустите 'install.sh' файл
- Чтобы запустить веб-интерфейс, запустите 'start_xtts_webui.sh'
- Откройте предпочтительный браузер и перейдите по локальному адресу, отображаемому в консоли.

### 2 Метод, Вручную
Для установки выполните следующие действия:
1. Убедитесь,`CUDA` установлена
2. Клонируйте репозиторий: `git clone https://github.com/daswer123/xtts-webui`.
3. Перейдите в папку: `cd xtts-webui`.
4. Создайте виртуальное окружение: `python -m venv venv`.
5. Активируйте виртуальную среду:
   - В Windows используйте: `venv\scripts\activate`.
   - В linux используйте: `source venv\bin\activate`.

6. Установите PyTorch и torchaudio с помощью pip:
- `pip install torch==2.1.1+cu118 torchaudio==2.1.1+cu118 --index-url https://download.pytorch.org/whl/cu118`.

7. Установите все зависимости из файла requirements.txt :
- `pip install -r requirements.txt`.

## Запуск интерфейса

Чтобы запустить интерфейс, выполните следующие действия:

#### Запуск XTTS WebUI :
Активируйте виртуальную среду:
```bash
venv/scripts/activate
```
или если вы работаете в Linux,
```bash
source venv/bin/activate
```
Затем запустите веб-интерфейс для xtts, выполнив следующую команду:
```bash
python app.py
```

Вот некоторые аргументы времени выполнения, которые можно использовать при запуске приложения:

| Аргумент | Значение по умолчанию | Описание |
| --- | --- | --- |
| -hs, --host | 127.0.0.1 | Хост, к которому нужно привязаться |
| -p, --port | 8010 | Номер порта для прослушивания |
| -d, --device | cuda | Какое устройство использовать (cpu или cuda)|
| -sf,--speaker_folder | speakers/ | Каталог, содержащий образцы говорящих |
|-o,--output |"output/" | Папка вывода |
|-v,-version |"v2.0.2" |Вы можете указать, какую версию xtts использовать. Вы можете указать имя пользовательской модели, для этого поместите папку в models и укажите имя папки в этом флаге|
|-l,--language  	|"auto"		|Язык Webui, вы можете увидеть доступные переводы в папке i18n/locale.|
|--lowvram || Включить режим low vram, который переключает модель в RAM, когда она не обрабатывается активно|
|--deepspeed ||Включить ускорение deepspeed. Работает на windows на python 3.10 и 3.11 |
|--share ||Позволяет использовать интерфейс вне локального компьютера|
|--rvc ||Включить постобработку RVC, все модели должны располагаться в папке rvc|

### TTS -> RVC

Модуль для RVC, вы можете включить модуль RVC для постобработки полученного звука, для этого вам нужно добавить флаг --rvc, если вы работаете в консоли, или записать его в файл запуска.

Для того чтобы модель работала в настройках RVC, вам нужно выбрать модель, которую вы должны сначала загрузить в папку voice2voice/rvc, модель и индексный файл должны быть вместе, индексный файл необязателен, каждая модель должна быть в отдельной папке.
